{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "영상 얼굴 식별 모듈 구현.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoyeVpNhN7B04kuG77q0GW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seonghunYang/face-recognition/blob/main/%EC%98%81%EC%83%81_%EC%96%BC%EA%B5%B4_%EC%8B%9D%EB%B3%84_%EB%AA%A8%EB%93%88_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDJK2SWNUeA4"
      },
      "source": [
        "##얼굴 식별 파이프라인\n",
        "1. face detection\n",
        "2. face alignment 및 정규화\n",
        "3. face representation\n",
        "4. face verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLWHv37VUJpg"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "%cd drive/MyDrive/i-mind-face-recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJBvvOIoUoYS"
      },
      "source": [
        "from deepface.commons import functions, distance as dst\n",
        "from deepface import DeepFace\n",
        "from retinaface import RetinaFace\n",
        "import time\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1IdZLx-Xu5Z"
      },
      "source": [
        "#face detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii0JcFWvXySu"
      },
      "source": [
        "# 이미지 사진 보여주고, rgb 변환한 값 return\n",
        "def showImg(img_path):\n",
        "  img_arr  = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(img_arr)\n",
        "  return img_arr\n",
        "\n",
        "def drawFrameWithBbox(frame, detected_faces, labels):\n",
        "  draw_frame = frame.copy()\n",
        "  idx = 0\n",
        "  for key in detected_faces.keys():\n",
        "    face = detected_faces[key]\n",
        "    face_area = face['facial_area']\n",
        "    left = face_area[0]\n",
        "    top = face_area[1]\n",
        "    right = face_area[2]\n",
        "    bottom = face_area[3]\n",
        "\n",
        "    cv2.rectangle(draw_frame, (left, top), (right, bottom), (255, 0, 0), 1)\n",
        "    cv2.putText(draw_frame, labels[idx], (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    landmarks = face['landmarks']\n",
        "    # landmark 표시\n",
        "    for key in landmarks:\n",
        "      cv2.circle(draw_frame, tuple(landmarks[key]), 1, (255, 0, 0), -1)\n",
        "    idx += 1\n",
        "  return draw_frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o43StSc8YOY6"
      },
      "source": [
        "#face alignment / normalization\n",
        "1. face crop\n",
        "2. face alignment\n",
        "3. face resize and normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzUy7X75YR0_"
      },
      "source": [
        "from retinaface.commons import postprocess\n",
        "import numpy as np\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MY5JuYgYcDV"
      },
      "source": [
        "def cropFace(img, area):\n",
        "  img_copy = img.copy()\n",
        "  left = area[0]\n",
        "  top = area[1]\n",
        "  right = area[2]\n",
        "  bottom = area[3]\n",
        "  return img_copy[top: bottom, left: right]\n",
        "\n",
        "def alignFace(img, landmarks):\n",
        "  left_eye = landmarks[\"left_eye\"]\n",
        "  right_eye = landmarks[\"right_eye\"]\n",
        "  nose = landmarks[\"nose\"]\n",
        "  mouth_right = landmarks[\"mouth_right\"]\n",
        "  mouth_left = landmarks[\"mouth_left\"]\n",
        "  img = postprocess.alignment_procedure(img, right_eye, left_eye, nose)\n",
        "  return img[:, :, ::-1]\n",
        "\n",
        "def resizeFace(img, target_size=(112, 112)):\n",
        "  factor_0 = target_size[0] / img.shape[0]\n",
        "  factor_1 = target_size[1] / img.shape[1]\n",
        "  factor = min(factor_0, factor_1)\n",
        "\n",
        "  dsize = (int(img.shape[1] * factor), int(img.shape[0] * factor))\n",
        "  img = cv2.resize(img, dsize)\n",
        "\n",
        "  diff_0 = target_size[0] - img.shape[0]\n",
        "  diff_1 = target_size[1] - img.shape[1]\n",
        "  img = np.pad(img, ((diff_0 // 2, diff_0 - diff_0 // 2), (diff_1 // 2, diff_1 - diff_1 // 2), (0, 0)), 'constant')\n",
        "  \n",
        "  if img.shape[0:2] != target_size:\n",
        "    img = cv2.resize(img, target_size)\n",
        "  \n",
        "  img_pixels = image.img_to_array(img)\n",
        "  img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "  img_pixels /= 255 #normalize input in [0, 1]\n",
        "\n",
        "  return img_pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y8aB45UY7Fh"
      },
      "source": [
        "def processFrame(frame, faces):\n",
        "  result = []\n",
        "  for key in faces.keys():\n",
        "    face = faces[key]\n",
        "    facial_area = face['facial_area']\n",
        "    # 얼굴 자르기\n",
        "    crop_face = cropFace(frame, facial_area)\n",
        "    # 얼굴 정렬\n",
        "    landmarks = face['landmarks']\n",
        "    align_face = alignFace(crop_face, landmarks)\n",
        "    #resize\n",
        "    resize_face = resizeFace(align_face)\n",
        "    result.append(resize_face)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}