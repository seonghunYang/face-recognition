{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "영상 얼굴 식별 모듈 구현.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMpPgGsfgABq5Uk7F/13IYU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seonghunYang/face-recognition/blob/main/%EC%98%81%EC%83%81_%EC%96%BC%EA%B5%B4_%EC%8B%9D%EB%B3%84_%EB%AA%A8%EB%93%88_%EA%B5%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDJK2SWNUeA4"
      },
      "source": [
        "##얼굴 식별 파이프라인\n",
        "1. face detection\n",
        "2. face alignment 및 정규화\n",
        "3. face representation\n",
        "4. face verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLWHv37VUJpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55cdffaf-44b4-42da-c80e-e2df4386eba3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "%cd drive/MyDrive/i-mind-face-recognition"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/i-mind-face-recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJBvvOIoUoYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b1e686-e6d6-4e32-99e1-2876fb88a48f"
      },
      "source": [
        "from deepface.commons import functions, distance as dst\n",
        "from deepface import DeepFace\n",
        "from retinaface import RetinaFace\n",
        "import time\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGfSavm8lygt",
        "outputId": "d185e070-f61a-4692-d222-66d2e260dfc0"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/f6/91c07f54c2162854f5028aaa13f576ca17a3bc0cf6da02c2ad5baddae128/wandb-0.10.33-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 7.4MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.5MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/9d/33fb698b92c137e26520ad27d98e21d84a4dc088e7ae683aca157469aad0/sentry_sdk-1.2.0-py2.py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 69.2MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (57.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6502 sha256=910fa323ca1879e67e81f1b8066e558302ac55dc370be5d78d2c293ad486248b\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8807 sha256=e3151f8c544aa66415a8f6beca24a6ef559e60d6f89505c535103c07ca55d06b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: shortuuid, configparser, subprocess32, sentry-sdk, docker-pycreds, smmap, gitdb, GitPython, pathtools, wandb\n",
            "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.2.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'wandb' from '/usr/local/lib/python3.7/dist-packages/wandb/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7xj8Amrl7Hu"
      },
      "source": [
        "wandb.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1IdZLx-Xu5Z"
      },
      "source": [
        "#face detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii0JcFWvXySu"
      },
      "source": [
        "# 이미지 사진 보여주고, rgb 변환한 값 return\n",
        "def showImg(img_path):\n",
        "  img_arr  = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(img_arr)\n",
        "  return img_arr\n",
        "\n",
        "def drawFrameWithBbox(frame, detected_faces, labels):\n",
        "  draw_frame = frame.copy()\n",
        "  idx = 0\n",
        "  for key in detected_faces.keys():\n",
        "    face = detected_faces[key]\n",
        "    face_area = face['facial_area']\n",
        "    left = face_area[0]\n",
        "    top = face_area[1]\n",
        "    right = face_area[2]\n",
        "    bottom = face_area[3]\n",
        "\n",
        "    cv2.rectangle(draw_frame, (left, top), (right, bottom), (255, 0, 0), 1)\n",
        "    cv2.putText(draw_frame, labels[idx], (int(left), int(top - 7)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    landmarks = face['landmarks']\n",
        "    # landmark 표시\n",
        "    for key in landmarks:\n",
        "      cv2.circle(draw_frame, tuple(landmarks[key]), 1, (255, 0, 0), -1)\n",
        "    idx += 1\n",
        "  return draw_frame"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o43StSc8YOY6"
      },
      "source": [
        "#face alignment / normalization\n",
        "1. face crop\n",
        "2. face alignment\n",
        "3. face resize and normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzUy7X75YR0_"
      },
      "source": [
        "from retinaface.commons import postprocess\n",
        "import numpy as np\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MY5JuYgYcDV"
      },
      "source": [
        "def cropFace(img, area):\n",
        "  img_copy = img.copy()\n",
        "  left = area[0]\n",
        "  top = area[1]\n",
        "  right = area[2]\n",
        "  bottom = area[3]\n",
        "  return img_copy[top: bottom, left: right]\n",
        "\n",
        "def alignFace(img, landmarks):\n",
        "  left_eye = landmarks[\"left_eye\"]\n",
        "  right_eye = landmarks[\"right_eye\"]\n",
        "  nose = landmarks[\"nose\"]\n",
        "  mouth_right = landmarks[\"mouth_right\"]\n",
        "  mouth_left = landmarks[\"mouth_left\"]\n",
        "  img = postprocess.alignment_procedure(img, right_eye, left_eye, nose)\n",
        "  return img[:, :, ::-1]\n",
        "\n",
        "def resizeFace(img, target_size=(112, 112)):\n",
        "  factor_0 = target_size[0] / img.shape[0]\n",
        "  factor_1 = target_size[1] / img.shape[1]\n",
        "  factor = min(factor_0, factor_1)\n",
        "\n",
        "  dsize = (int(img.shape[1] * factor), int(img.shape[0] * factor))\n",
        "  img = cv2.resize(img, dsize)\n",
        "\n",
        "  diff_0 = target_size[0] - img.shape[0]\n",
        "  diff_1 = target_size[1] - img.shape[1]\n",
        "  img = np.pad(img, ((diff_0 // 2, diff_0 - diff_0 // 2), (diff_1 // 2, diff_1 - diff_1 // 2), (0, 0)), 'constant')\n",
        "  \n",
        "  if img.shape[0:2] != target_size:\n",
        "    img = cv2.resize(img, target_size)\n",
        "  \n",
        "  img_pixels = image.img_to_array(img)\n",
        "  img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "  img_pixels /= 255 #normalize input in [0, 1]\n",
        "\n",
        "  return img_pixels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y8aB45UY7Fh"
      },
      "source": [
        "def processFrame(frame, faces):\n",
        "  result = []\n",
        "  for key in faces.keys():\n",
        "    face = faces[key]\n",
        "    facial_area = face['facial_area']\n",
        "    # 얼굴 자르기\n",
        "    crop_face = cropFace(frame, facial_area)\n",
        "    # 얼굴 정렬\n",
        "    landmarks = face['landmarks']\n",
        "    align_face = alignFace(crop_face, landmarks)\n",
        "    #resize\n",
        "    resize_face = resizeFace(align_face)\n",
        "    result.append(resize_face)\n",
        "  return result"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "breJpShVZQsG"
      },
      "source": [
        "#face representation and verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmRMyg1OZVN8"
      },
      "source": [
        "import os\n",
        "from deepface.basemodels import ArcFace\n",
        "\n",
        "def createEmbedingDB(db_folder_path, labels, img_show=False):\n",
        "  db = {\n",
        "      \"labels\": labels,\n",
        "      \"embeding\": []\n",
        "  }\n",
        "  img_paths = os.listdir(db_folder_path)\n",
        "  model = ArcFace.loadModel()\n",
        "  for img_path in img_paths:\n",
        "    img_path = db_folder_path + \"/\" + img_path\n",
        "    \n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "\n",
        "    faces = RetinaFace.detect_faces(img_path=img)\n",
        "    # bbox\n",
        "    if (type(faces) == dict):\n",
        "      label = img_path[:img_path.rfind(\".\")]\n",
        "      process_face_imgs = processFrame(img, faces)\n",
        "      # 임베딩\n",
        "      for face_img in process_face_imgs:\n",
        "        embedding_img = model.predict(face_img)[0]\n",
        "        db[\"embeding\"].append(embedding_img)\n",
        "      if img_show:\n",
        "        img_bbox = drawFrameWithBbox(img, faces, [label])\n",
        "        plt.imshow(img_bbox)\n",
        "        plt.show()\n",
        "  return db"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFgdW8I4ZZTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b23588-3e74-4ec6-9852-bf7ed4d69457"
      },
      "source": [
        "labels = [\"john\", \"piglet\", \"john\", \"piglet\"]\n",
        "db = createEmbedingDB(\"/content/db\", labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arcface_weights.h5  will be downloaded to  /root/.deepface/weights/arcface_weights.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/arcface_weights.h5\n",
            "To: /root/.deepface/weights/arcface_weights.h5\n",
            "100%|██████████| 137M/137M [00:01<00:00, 94.4MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100%|██████████| 119M/119M [00:03<00:00, 35.8MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s1hgPDZZwGd"
      },
      "source": [
        "from deepface.commons import functions, distance as dst\n",
        "\n",
        "def faceIdentify(img, db, model, metric=\"cosine\"):\n",
        "  img_embeding = model.predict(img)[0]\n",
        "  for idx, db_embeding in enumerate(db['embeding']):\n",
        "    distance = cosineDistance(img_embeding, db_embeding, metric)\n",
        "    threshold = findThreshold(metric)\n",
        "\n",
        "    if distance <= threshold:\n",
        "      return db['labels'][idx]\n",
        "  return \"unknown\"\n",
        "\n",
        "def cosineDistance(img1_embedding, img2_embedding, metric):\n",
        "  if metric == 'cosine':\n",
        "    distance = dst.findCosineDistance(img1_embedding, img2_embedding)\n",
        "  elif metric == 'euclidean':\n",
        "    distance = dst.findEuclideanDistance(img1_embedding, img2_embedding)\n",
        "  elif metric == 'euclidean_l2':\n",
        "    distance = dst.findEuclideanDistance(dst.l2_normalize(img1_embedding), dst.l2_normalize(img2_embedding))\n",
        "  return distance\n",
        "\n",
        "def findThreshold(metric):\n",
        "   if metric == 'cosine':\n",
        "      return 0.6871912959056619\n",
        "   elif metric == 'euclidean':\n",
        "      return 4.1591468986978075\n",
        "   elif metric == 'euclidean_l2':\n",
        "      return 1.1315718048269017"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpxzLXfka5fs"
      },
      "source": [
        "def faecRecognition(input_path, output_path, db):\n",
        "\n",
        "  cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "  codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "  vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "  vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n",
        "\n",
        "  frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  print(\"총 Frame 갯수: \", frame_cnt)\n",
        "  btime = time.time()\n",
        "\n",
        "  # retinaface model load\n",
        "  detect_model = RetinaFace.build_model()\n",
        "  identify_model = ArcFace.loadModel()\n",
        "  while True:\n",
        "    hasFrame, img_frame = cap.read()\n",
        "    if not hasFrame:\n",
        "      print('처리 완료')\n",
        "      break\n",
        "    stime = time.time()\n",
        "    #retinaface로 얼굴 detection\n",
        "    faces = RetinaFace.detect_faces(img_path=img_frame, model=detect_model)\n",
        "    # bbox\n",
        "    if (type(faces) == dict):\n",
        "      process_face_imgs = processFrame(img_frame, faces)\n",
        "      identities = []\n",
        "      for face_img in process_face_imgs:\n",
        "        identity = faceIdentify(face_img, db, identify_model)\n",
        "        identities.append(identity)\n",
        "    img_frame = drawFrameWithBbox(img_frame, faces, identities)\n",
        "\n",
        "    print('frame별 detection 수행 시간:', round(time.time() - stime, 4))\n",
        "    vid_writer.write(img_frame)\n",
        "\n",
        "  vid_writer.release()\n",
        "  cap.release()\n",
        "\n",
        "  print(\"최종 완료 수행 시간: \", round(time.time() - btime, 4))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi1OsGqeOwO0"
      },
      "source": [
        "faecRecognition(\"/content/cctv_200_test.mp4\", \"/content/cctv_200_result.mp4\", db)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nTcSlpdmuSD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}